{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import parse\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crawl(url) :\n",
    "    print(\"Crawling webtoon urls..\")\n",
    "    n_list = getWebtoons(url)\n",
    "    print(\"Crawling episode urls..\")\n",
    "    id_list = getEpisodes(n_list)\n",
    "    print(\"Crawling Comments..\")\n",
    "    getComments(id_list)\n",
    "    \n",
    "def getWebtoons(url):\n",
    "    nickname_list=[]\n",
    "    html = request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    jsondata = json.loads(soup.text)\n",
    "            \n",
    "    for i in jsondata['data']: # every webtoon\n",
    "        n = i.get('nickname')\n",
    "        nickname_list.append(n)\n",
    "        \n",
    "    return nickname_list\n",
    "        \n",
    "def getEpisodes(nickname_list) :\n",
    "    id_list=[]\n",
    "    for n in nickname_list :\n",
    "        URL = 'http://webtoon.daum.net/data/pc/webtoon/view/' + n\n",
    "        html = request.urlopen(URL).read()\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        jsondata = json.loads(soup.text)\n",
    "        \n",
    "        try :\n",
    "            for i in jsondata['data'].get('webtoon').get('webtoonEpisodes'):\n",
    "                e = i.get('id')\n",
    "                id_list.append(e)\n",
    "        except:\n",
    "            print(\"not working!!!!! adult webtoon !!! \",URL)\n",
    "    return id_list\n",
    "            \n",
    "def getComments(id_list) :\n",
    "    \n",
    "    for i in id_list:\n",
    "        URL = 'http://webtoon.daum.net/webtoon/viewer/' + str(i) #????\n",
    "        html = request.urlopen(URL).read()\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_mon = 'http://webtoon.daum.net/data/pc/webtoon/list_serialized/mon'\n",
    "url_tue = 'http://webtoon.daum.net/data/pc/webtoon/list_serialized/tue'\n",
    "url_wed = 'http://webtoon.daum.net/data/pc/webtoon/list_serialized/wed'\n",
    "url_thu = 'http://webtoon.daum.net/data/pc/webtoon/list_serialized/thu'\n",
    "url_fri = 'http://webtoon.daum.net/data/pc/webtoon/list_serialized/fri'\n",
    "url_sat = 'http://webtoon.daum.net/data/pc/webtoon/list_serialized/sat'\n",
    "url_sun = 'http://webtoon.daum.net/data/pc/webtoon/list_serialized/sun'\n",
    "url_finished = 'http://webtoon.daum.net/data/pc/webtoon/list_finished/' \n",
    "\n",
    "#url_list = [url_mon, url_tue, url_wed, url_thu, url_fri, url_sat, url_sun, url_finished]\n",
    "url_list = [url_mon, url_tue]\n",
    "for i in url_list:\n",
    "    Crawl(i)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
