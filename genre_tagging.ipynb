{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "genre_tagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFwoP0yP+Yk3K1rX2lb+2G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bigdata-webtoon-recommendation/webtoon-crawlers/blob/main/genre_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2IIiRBaWnhT"
      },
      "source": [
        "import csv\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import operator\n",
        "import pandas as pd\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeEI9lw2l1e3",
        "outputId": "258b4bf6-a04e-48c2-9e8c-a8117e29e6e6"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL2S3oebRJ1S"
      },
      "source": [
        "\n",
        "## For Daum webtoon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2L6iv-Xave"
      },
      "source": [
        "# 네이버, 다음 통합 장르 구분 - episode, story, daily_life, comic, fantasy, action, drama, romance, thriller, period_drama, sports, campus_life\n",
        "\n",
        "# 다음웹툰 장르에서 '성인' 의 경우 다른feature로 적용하므로 제외\n",
        "# 다음웹툰 장르에서 '지식'의 경우 에피소드로 넣어둠\n",
        "# 다음웹툰 장르에서 '학원' 장르 따로 빼서 12번째 기준으로 둠\n",
        "\n",
        "episode_terms = ['에피소드','지식']               # 1\n",
        "story_terms = ['스토리']                   # 2\n",
        "daily_life_terms = ['일상']         # 3\n",
        "comic_terms = ['개그', '코믹']             # 4\n",
        "fantasy_terms = ['판타지']                 # 5\n",
        "action_terms = ['액션','무협']             # 6\n",
        "drama_terms = ['드라마']                   # 7\n",
        "romance_terms = ['순정','감성']            # 8\n",
        "thriller_terms = ['스릴러','공포','미스터리']  # 9\n",
        "period_drama_terms = ['시대극']            # 10\n",
        "sports_terms = ['스포츠']                  # 11\n",
        "campus_life_terms = ['학원']               # 12\n",
        "\n",
        "with open('crawling_result_daum.csv', encoding=\"utf-8\") as csv_file:\n",
        "  with open('crawling_genre_tagging_daum_v2.csv',mode='w',newline='',encoding='utf-8') as my_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    my_writer = csv.writer(my_file,delimiter=',')\n",
        "    my_writer.writerow(['episode','story','daily_life','comic','fantasy','action','drama','romance','thriller','period_drama','sports','campus_life'])\n",
        "\n",
        "    line_count = 0\n",
        "    for row in csv_reader:  #csv_reader:\n",
        "      if line_count == 0:\n",
        "        line_count = line_count + 1 #다음의 경우 헤더있음. 네이버는 이거 주석처리!!\n",
        "      else:\n",
        "        webtoon_name = row[1]\n",
        "\n",
        "        #네이버는 row[4], 다음은 row[5]\n",
        "        original_genre = row[5]\n",
        "\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        tokenizer = RegexpTokenizer(r'\\w+')\n",
        "        original_genre_tokens = tokenizer.tokenize(original_genre)\n",
        "\n",
        "        #print(original_genre_tokens)\n",
        "\n",
        "        if original_genre_tokens:   # 토큰화된 장르가 하나라도 존재하는 경우\n",
        "\n",
        "          # 장르 1 : episode\n",
        "          if list(set(original_genre_tokens) & set(episode_terms)):\n",
        "            cur_episode = '1'\n",
        "          else:\n",
        "            cur_episode = '0'\n",
        "          \n",
        "          # 장르 2 : story\n",
        "          if list(set(original_genre_tokens) & set(story_terms)):\n",
        "            cur_story = '1'\n",
        "          else:\n",
        "            cur_story = '0'\n",
        "\n",
        "          # 장르 3 : daily_life\n",
        "          if list(set(original_genre_tokens) & set(daily_life_terms)):\n",
        "            cur_daily_life = '1'\n",
        "          else:\n",
        "            cur_daily_life = '0'\n",
        "\n",
        "          # 장르 4 : comic\n",
        "          if list(set(original_genre_tokens) & set(comic_terms)):\n",
        "            cur_comic = '1'\n",
        "          else:\n",
        "            cur_comic = '0'\n",
        "\n",
        "          # 장르 5 : fantasy\n",
        "          if list(set(original_genre_tokens) & set(fantasy_terms)):\n",
        "            cur_fantasy = '1'\n",
        "          else:\n",
        "            cur_fantasy = '0'\n",
        "\n",
        "          # 장르 6 : action\n",
        "          if list(set(original_genre_tokens) & set(action_terms)):\n",
        "            cur_action = '1'\n",
        "          else:\n",
        "            cur_action = '0'\n",
        "\n",
        "          # 장르 7 : drama\n",
        "          if list(set(original_genre_tokens) & set(drama_terms)):\n",
        "            cur_drama = '1'\n",
        "          else:\n",
        "            cur_drama = '0'\n",
        "\n",
        "          # 장르 8 : romance\n",
        "          if list(set(original_genre_tokens) & set(romance_terms)):\n",
        "            cur_romance = '1'\n",
        "          else:\n",
        "            cur_romance = '0'\n",
        "\n",
        "          # 장르 9 : thriller\n",
        "          if list(set(original_genre_tokens) & set(thriller_terms)):\n",
        "            cur_thriller = '1'\n",
        "          else:\n",
        "            cur_thriller = '0'\n",
        "\n",
        "          # 장르 10 : period\n",
        "          if list(set(original_genre_tokens) & set(period_drama_terms)):\n",
        "            cur_period_drama = '1'\n",
        "          else:\n",
        "            cur_period_drama = '0'\n",
        "\n",
        "          # 장르 11 : sports\n",
        "          if list(set(original_genre_tokens) & set(sports_terms)):\n",
        "            cur_sports = '1'\n",
        "          else:\n",
        "            cur_sports = '0'\n",
        "\n",
        "          # 장르 12 : campus_life\n",
        "          if list(set(original_genre_tokens) & set(campus_life_terms)):\n",
        "            cur_campus_life = '1'\n",
        "          else:\n",
        "            cur_campus_life= '0'\n",
        "\n",
        "        else:\n",
        "          cur_episode = None\n",
        "          cur_story = None\n",
        "          cur_daily_life = None\n",
        "          cur_comic = None\n",
        "          cur_fantasy = None\n",
        "          cur_action = None\n",
        "          cur_drama = None\n",
        "          cur_romance = None\n",
        "          cur_thriller = None\n",
        "          cur_period_drama = None\n",
        "          cur_sports = None\n",
        "          cur_campus_life = None\n",
        "\n",
        "        my_writer.writerow([cur_episode, cur_story, cur_daily_life, cur_comic, cur_fantasy, cur_action, cur_drama, cur_romance, cur_thriller, cur_period_drama, cur_sports, cur_campus_life])\n",
        "        line_count = line_count +1\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwHkcqeJS7Qm"
      },
      "source": [
        "## For Naver Webtoon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3bI8d5fQewk",
        "outputId": "9c22695c-73d0-4ff6-a969-b676502b3cc8"
      },
      "source": [
        "pip install konlpy"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.9MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: tweepy, beautifulsoup4, JPype1, colorama, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrOUDxocP2eA"
      },
      "source": [
        "from konlpy.tag import Okt  \n",
        "okt=Okt()  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk4l02YuS85W"
      },
      "source": [
        "# 네이버, 다음 통합 장르 구분 - episode, story, daily_life, comic, fantasy, action, drama, romance, thriller, period_drama, sports, campus_life\n",
        "\n",
        "# 옴니버스는 제외함\n",
        "# 네이버 장르에는 '학원' 장르가 없다 -> 한줄 소개에서 키워드 추출 이후 -> '학생' '학원' '학교' '교내' '교실'가 나오면 campus_life 장르로 분류\n",
        "# 다음웹툰 장르에서 '학원' 장르 따로 빼서 12번째 기준으로 둠\n",
        "\n",
        "episode_terms = ['에피소드','지식']               # 1\n",
        "story_terms = ['스토리']                   # 2\n",
        "daily_life_terms = ['일상']         # 3\n",
        "comic_terms = ['개그', '코믹']             # 4\n",
        "fantasy_terms = ['판타지']                 # 5\n",
        "action_terms = ['액션','무협']             # 6\n",
        "drama_terms = ['드라마']                   # 7\n",
        "romance_terms = ['순정','감성']            # 8\n",
        "thriller_terms = ['스릴러','공포','미스터리']  # 9\n",
        "period_drama_terms = ['시대극']            # 10\n",
        "sports_terms = ['스포츠']                  # 11\n",
        "\n",
        "# 네이버에서는 한 줄 줄거리에서 학원장르를 결정하기 위해 terms추가\n",
        "campus_life_terms = ['학원', '학생', '학교','교내','교실']               # 12\n",
        "\n",
        "with open('crawling_result_naver.csv', encoding=\"utf-8\") as csv_file:\n",
        "  with open('crawling_genre_tagging_naver_v2.csv',mode='w',newline='',encoding='utf-8') as my_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    my_writer = csv.writer(my_file,delimiter=',')\n",
        "    my_writer.writerow(['episode','story','daily_life','comic','fantasy','action','drama','romance','thriller','period_drama','sports','campus_life'])\n",
        "\n",
        "    line_count = 0\n",
        "    for row in csv_reader:  #csv_reader:\n",
        "      #if line_count == 0:\n",
        "      #  line_count = line_count + 1 #다음의 경우 헤더있음. 네이버는 이거 주석처리!!\n",
        "      #else:\n",
        "        webtoon_name = row[1]\n",
        "        webtoon_synopsis = row[6]\n",
        "        original_genre = row[4]\n",
        "\n",
        "        # 간단한 띄어쓰기, 쉼표 등의 불용어 제거에는 english 불용어 제거를 이용함\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "        # 장르 분류를 위해 ['판타지', '액션'] -> 판타지, 액션 으로 토큰화\n",
        "        original_genre_tokens = tokenizer.tokenize(original_genre)\n",
        "\n",
        "        # 학원 장르 분류를 위해 한줄 줄거리에서 토큰화\n",
        "        campus_life_tokens = okt.nouns(webtoon_synopsis)\n",
        "\n",
        "\n",
        "        if original_genre_tokens:   # 토큰화된 장르가 하나라도 존재하는 경우\n",
        "\n",
        "          # 장르 1 : episode\n",
        "          if list(set(original_genre_tokens) & set(episode_terms)):\n",
        "            cur_episode = '1'\n",
        "          else:\n",
        "            cur_episode = '0'\n",
        "          \n",
        "          # 장르 2 : story\n",
        "          if list(set(original_genre_tokens) & set(story_terms)):\n",
        "            cur_story = '1'\n",
        "          else:\n",
        "            cur_story = '0'\n",
        "\n",
        "          # 장르 3 : daily_life\n",
        "          if list(set(original_genre_tokens) & set(daily_life_terms)):\n",
        "            cur_daily_life = '1'\n",
        "          else:\n",
        "            cur_daily_life = '0'\n",
        "\n",
        "          # 장르 4 : comic\n",
        "          if list(set(original_genre_tokens) & set(comic_terms)):\n",
        "            cur_comic = '1'\n",
        "          else:\n",
        "            cur_comic = '0'\n",
        "\n",
        "          # 장르 5 : fantasy\n",
        "          if list(set(original_genre_tokens) & set(fantasy_terms)):\n",
        "            cur_fantasy = '1'\n",
        "          else:\n",
        "            cur_fantasy = '0'\n",
        "\n",
        "          # 장르 6 : action\n",
        "          if list(set(original_genre_tokens) & set(action_terms)):\n",
        "            cur_action = '1'\n",
        "          else:\n",
        "            cur_action = '0'\n",
        "\n",
        "          # 장르 7 : drama\n",
        "          if list(set(original_genre_tokens) & set(drama_terms)):\n",
        "            cur_drama = '1'\n",
        "          else:\n",
        "            cur_drama = '0'\n",
        "\n",
        "          # 장르 8 : romance\n",
        "          if list(set(original_genre_tokens) & set(romance_terms)):\n",
        "            cur_romance = '1'\n",
        "          else:\n",
        "            cur_romance = '0'\n",
        "\n",
        "          # 장르 9 : thriller\n",
        "          if list(set(original_genre_tokens) & set(thriller_terms)):\n",
        "            cur_thriller = '1'\n",
        "          else:\n",
        "            cur_thriller = '0'\n",
        "\n",
        "          # 장르 10 : period\n",
        "          if list(set(original_genre_tokens) & set(period_drama_terms)):\n",
        "            cur_period_drama = '1'\n",
        "          else:\n",
        "            cur_period_drama = '0'\n",
        "\n",
        "          # 장르 11 : sports\n",
        "          if list(set(original_genre_tokens) & set(sports_terms)):\n",
        "            cur_sports = '1'\n",
        "          else:\n",
        "            cur_sports = '0'\n",
        "\n",
        "          # 장르 12 : campus_life\n",
        "          if list(set(campus_life_tokens) & set(campus_life_terms)):\n",
        "            cur_campus_life = '1'\n",
        "          else:\n",
        "            cur_campus_life= '0'\n",
        "\n",
        "        else:\n",
        "          cur_episode = None\n",
        "          cur_story = None\n",
        "          cur_daily_life = None\n",
        "          cur_comic = None\n",
        "          cur_fantasy = None\n",
        "          cur_action = None\n",
        "          cur_drama = None\n",
        "          cur_romance = None\n",
        "          cur_thriller = None\n",
        "          cur_period_drama = None\n",
        "          cur_sports = None\n",
        "          cur_campus_life = None\n",
        "\n",
        "        my_writer.writerow([cur_episode, cur_story, cur_daily_life, cur_comic, cur_fantasy, cur_action, cur_drama, cur_romance, cur_thriller, cur_period_drama, cur_sports, cur_campus_life])\n",
        "        line_count = line_count +1\n",
        "\n",
        "      #else:\n",
        "      #    break\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}