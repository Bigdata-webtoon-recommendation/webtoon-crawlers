{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "genre_tagging.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNX6chZna2vXgjjaWBm+7lt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bigdata-webtoon-recommendation/webtoon-crawlers/blob/main/genre_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2IIiRBaWnhT"
      },
      "source": [
        "import csv\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import operator\n",
        "import pandas as pd\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeEI9lw2l1e3",
        "outputId": "afab1c7e-4def-4b58-f8d0-c64cdfa73679"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2L6iv-Xave"
      },
      "source": [
        "# 네이버, 다음 통합 장르 구분 - episode, story, daily_life, comic, fantasy, action, drama, romance, thriller, period_drama,  sports\n",
        "\n",
        "# 다음웹툰 장르에서 '성인' 의 경우 다른feature로 적용하므로 제외\n",
        "# 네이버 장르에서 '옴니버스'의 경우 다음에서 매칭되는 기준이 없어서 제외 - 어차피 장르가 옴니버스 1개로 tagging된 경우는 없으므로 ok\n",
        "# 다음웹툰 장르에서 '지식'의 경우 일상으로 넣어둠 - '지식'하나만 tagging된 경우 있어서 일상으로 속하게 해둠\n",
        "\n",
        "episode_terms = ['에피소드']               # 1\n",
        "story_terms = ['스토리']                   # 2\n",
        "daily_life_terms = ['일상','학원','지식']  # 3\n",
        "comic_terms = ['개그', '코믹']             # 4\n",
        "fantasy_terms = ['판타지']                 # 5\n",
        "action_terms = ['액션','무협']             # 6\n",
        "drama_terms = ['드라마']                   # 7\n",
        "romance_terms = ['순정','감성']            # 8\n",
        "thriller_terms = ['스릴러','공포','미스터리']  # 9\n",
        "period_drama_terms = ['시대극']            # 10\n",
        "sports_terms = ['스포츠']                  # 11\n",
        "\n",
        "with open('crawling_result_daum.csv', encoding=\"utf-8\") as csv_file:\n",
        "  with open('crawling_genre_tagging_daum.csv',mode='w',newline='',encoding='utf-8') as my_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    my_writer = csv.writer(my_file,delimiter=',')\n",
        "    my_writer.writerow(['episode','story','daily_life','comic','fantasy','action','drama','romance','thriller','period_drama','sports'])\n",
        "\n",
        "    line_count = 0\n",
        "    for row in csv_reader:  #csv_reader:\n",
        "      if line_count == 0:\n",
        "        line_count = line_count + 1 #다음의 경우 헤더있음. 네이버는 이거 주석처리!!\n",
        "      else:\n",
        "        webtoon_name = row[1]\n",
        "\n",
        "        #네이버는 row[4], 다음은 row[5]\n",
        "        original_genre = row[5]\n",
        "\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        tokenizer = RegexpTokenizer(r'\\w+')\n",
        "        original_genre_tokens = tokenizer.tokenize(original_genre)\n",
        "\n",
        "        #print(original_genre_tokens)\n",
        "\n",
        "        if original_genre_tokens:   # 토큰화된 장르가 하나라도 존재하는 경우\n",
        "\n",
        "          # 장르 1 : episode\n",
        "          if list(set(original_genre_tokens) & set(episode_terms)):\n",
        "            cur_episode = '1'\n",
        "          else:\n",
        "            cur_episode = '0'\n",
        "          \n",
        "          # 장르 2 : story\n",
        "          if list(set(original_genre_tokens) & set(story_terms)):\n",
        "            cur_story = '1'\n",
        "          else:\n",
        "            cur_story = '0'\n",
        "\n",
        "          # 장르 3 : daily_life\n",
        "          if list(set(original_genre_tokens) & set(daily_life_terms)):\n",
        "            cur_daily_life = '1'\n",
        "          else:\n",
        "            cur_daily_life = '0'\n",
        "\n",
        "          # 장르 4 : comic\n",
        "          if list(set(original_genre_tokens) & set(comic_terms)):\n",
        "            cur_comic = '1'\n",
        "          else:\n",
        "            cur_comic = '0'\n",
        "\n",
        "          # 장르 5 : fantasy\n",
        "          if list(set(original_genre_tokens) & set(fantasy_terms)):\n",
        "            cur_fantasy = '1'\n",
        "          else:\n",
        "            cur_fantasy = '0'\n",
        "\n",
        "          # 장르 6 : action\n",
        "          if list(set(original_genre_tokens) & set(action_terms)):\n",
        "            cur_action = '1'\n",
        "          else:\n",
        "            cur_action = '0'\n",
        "\n",
        "          # 장르 7 : drama\n",
        "          if list(set(original_genre_tokens) & set(drama_terms)):\n",
        "            cur_drama = '1'\n",
        "          else:\n",
        "            cur_drama = '0'\n",
        "\n",
        "          # 장르 8 : romance\n",
        "          if list(set(original_genre_tokens) & set(romance_terms)):\n",
        "            cur_romance = '1'\n",
        "          else:\n",
        "            cur_romance = '0'\n",
        "\n",
        "          # 장르 9 : thriller\n",
        "          if list(set(original_genre_tokens) & set(thriller_terms)):\n",
        "            cur_thriller = '1'\n",
        "          else:\n",
        "            cur_thriller = '0'\n",
        "\n",
        "          # 장르 10 : period\n",
        "          if list(set(original_genre_tokens) & set(period_drama_terms)):\n",
        "            cur_period_drama = '1'\n",
        "          else:\n",
        "            cur_period_drama = '0'\n",
        "\n",
        "          # 장르 11 : sports\n",
        "          if list(set(original_genre_tokens) & set(sports_terms)):\n",
        "            cur_sports = '1'\n",
        "          else:\n",
        "            cur_sports = '0'\n",
        "\n",
        "        else:\n",
        "          cur_episode = None\n",
        "          cur_story = None\n",
        "          cur_daily_life = None\n",
        "          cur_comic = None\n",
        "          cur_fantasy = None\n",
        "          cur_action = None\n",
        "          cur_drama = None\n",
        "          cur_romance = None\n",
        "          cur_thriller = None\n",
        "          cur_period_drama = None\n",
        "          cur_sports = None\n",
        "\n",
        "        my_writer.writerow([cur_episode, cur_story, cur_daily_life, cur_comic, cur_fantasy, cur_action, cur_drama, cur_romance, cur_thriller, cur_period_drama, cur_sports])\n",
        "        line_count = line_count +1\n",
        "\n",
        "      #else:\n",
        "      #    break\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}